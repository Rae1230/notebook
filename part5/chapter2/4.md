---
sort: 4
---

# Value Function Approximation

## 4.1 Introduction

### 4.1.1 Scaling up RL: VFA

&emsp;&emsp;对于大规模的强化学习问题，应该如何扩展无模型方法来进行预测和控制呢？

&emsp;&emsp;在表格型方法中，我们用一个查找表来表示价值函数。每个状态$$s$$都有一个条目$$V(s)$$，每个状态-动作对$$s, a$$都有一个条目$$Q(s, a)$$。

<figure><img src="./images/4-1.JPG" width=250px></figure>

&emsp;&emsp;而在大规模的MDPs中，有过多的状态或动作需要存储，独立地学习每个状态的值所需的时间也过多，所以表格型算法无法解决。

问：如何避免为每个状态显式学习或存储以下内容呢？  
1. 动态或奖励模型
2. 价值函数、状态-动作函数
3. 策略  

解：用函数近似来估计
$$\begin{aligned}
    \hat{v}(s,\mathbf{w}) & \approx v_{\pi}(s)       \\
    \hat{q}(s,a,\mathbf{w}) & \approx q_{\pi}(s,a)   \\
    \hat{\pi}(a,s,\mathbf{w}) & \approx \pi(a \vert s)   \\
\end{aligned}
$$  
&emsp;&emsp;从可见状态推广到不可见状态  
&emsp;&emsp;用MC或TD学习来更新参数$$w$$

<figure>
    <img src="./images/4-2.JPG" width=300px>
    <figcaption>几种函数设计</figcaption>
</figure>

有很多可行的function approximators：  
1. 特征的线性结合
2. 神经网络
3. 决策树
4. 最近邻居

本课程将聚焦可微的函数逼近器：linear feature representations和neural networks。

<figure><img src="./images/4-3.JPG" width=250px></figure>

&emsp;&emsp;首先，我们来回顾一下梯度下降。函数$$J(\mathbf{w})$$是对参数向量$$\mathbf{w}$$可微，目标是找到能最小化$$J$$的参数$$\mathbf{w}^*$$。定义$$J(\mathbf{w})$$的梯度为

$$  \nabla_{\mathbf{w}} J(\mathbf{w}) 
=   \left[  \frac{\partial J(\mathbf{w})}{\partial w_1}, 
            \frac{\partial J(\mathbf{w})}{\partial w_2}, \cdots, 
            \frac{\partial J(\mathbf{w})}{\partial w_n} 
    \right]^T   $$

向负梯度方向调整$$\mathbf{w}$$，其$$\alpha$$为步长

$$\Delta \mathbf{w} = -\frac{1}{2} \alpha \nabla_{\mathbf{w}} J(\mathbf{w})$$

Value Function Approximation with an Oracle：  
&emsp;&emsp;假设我们有一个预言可以知道任何给定状态$$s$$的真实价值$$v_{\pi}(s)$$，目标是找到与$$v_{\pi}(s)$$最近似的表达。因此，使用均方误差并将损失函数定义为

$$  J(\mathbf{w})
=   \mathbb{E}_{\pi} \big[ (v_{\pi}(s) - \hat{v}(s,\mathbf{w}))^2 \big]
$$

沿着梯度下降找到一个局部最小值

$$\begin{aligned}
    \Delta \mathbf{w} &= -\frac{1}{2} \alpha \nabla_{\mathbf{w}} J(\mathbf{w})   \\
    \mathbf{w}_{t+1} &= \mathbf{w}_t + \Delta \mathbf{w}
\end{aligned}$$

### 4.1.2 Linear VFA

&emsp;&emsp;用一个特征向量$$\mathbf{x}(s) = (x_1(s), \ldots, x_n(s))^T$$来表示状态

<figure><img src="./images/4-4.JPG" width=500px></figure>

用特征的线性组合来表示价值函数

$$  \hat{v}(s, \mathbf{w})
=   \mathbf{x}(s)^T \mathbf{w}
=   \sum_{j=1}^n x_j(s) w_j
$$

目标函数中$$\mathbf{w}$$项是二次的

$$  J(\mathbf{w})
=   \mathbb{E}_{\pi} \big[ (v_{\pi}(s) - \mathbf{x}(s)^T \mathbf{w})^2 \big]
$$

因此更新规则很简单，$$\color{green}{\text{update} = \text{step size} \times \text{prediction error} \times \text{feature value}}$$

$$  \Delta \mathbf{w}
=  \alpha[v_{\pi}(s) - \hat{v}(s,\mathbf{w})] \mathbf{x}(s)
$$

随机梯度下降会收敛到全局最优。因为在线性情况下，只有一个最优值，因此局部最优值会自动收敛到或接近全局最优值。

**具有查表功能的线性值函数逼近**

&emsp;&emsp;查表是线性值函数逼近的一种特殊情况。查表特征是one-hot vector（独热编码）

$$  \mathbf{x}^{\text{table}}(s)
=   [1(s=s_1), \ldots, 1(s=s_n)]^T
$$

可以看到参数向量$$\mathbf{w}$$上的每个元素表示每个单独状态的值

$$  \hat{v}(s, \mathbf{w})
=   [1(s=s_1), \ldots, 1(s=s_n)][w_1, \ldots, w_n]^T
$$

因此，$$\hat{v}(s_k, \mathbf{w}) = w_k$$。

## 4.2 VFA for Prediction


## 4.3 VFA for Control
Least Square Prediction & Control
## 4.4 Deep Q networks 
<br />
<!-- 蓝 -->
<font color="#3399ff"></font>
<!-- 绿 --><!-- #33cc00 -->
<b><font color="#00B050"></font></b>
<!-- 橙 -->
<font color="#FF4500"></font>