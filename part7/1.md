---
sort: 1
---

# 决策树

## 1.1 Basic decision tree learning

#### Classical targeting problems

* 非数值数据（<font color="#3399ff">nominal</font> data）的分类问题
* 离散
* 没用相似的自然解释
* 一般没有排序

#### Representation

&emsp;&emsp;<font color="#3399ff">属性表</font>而不是真值的向量。

#### Decision tree — concepts

<center>
    <figure>
        <img src="./images/1-1.JPG" width=360px>
    </figure>
</center>

## 1.2 Classical decision tree algorithms

### 1.2.1 CART （分类与回归树）

一般框架：
* 利用训练数据构造一棵决策树
* 决策树将逐步将训练样本分解成越来越小的子集
* 当每个子集都是纯的时停止
* 或者当结果是可接受的时候

#### ID3

自顶向下，贪心搜索

递归算法

主循环：
* A：下一步的<font color="#3399ff">最佳</font>决策属性
* 把A作为节点的决策属性
* 对于$$A(vi)$$的每个值，创建新的节点后代
* 将训练示例排序到叶节点
* 如果<font color="#3399ff">训练样本完全分类</font>，则RETURN，  
&emsp;&emsp;Else向下取到新的叶节点





<!-- 蓝 -->
<font color="#3399ff"></font>
<!-- 绿 --><!-- #33cc00 -->
<b><font color="#00B050"></font></b>
<!-- 橙 -->
<font color="#FF4500"></font>